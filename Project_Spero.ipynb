{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Spero - RealSense Object Detection & Tracking\n",
    "\n",
    "This notebook consolidates the data collection, training, inference, and tracking modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import random\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===== CI / Notebook Execution Controls =====\n",
    "# These flags let GitHub Actions (papermill/nbclient) run the notebook safely.\n",
    "CI = os.getenv(\"CI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "RUN_DATA_COLLECTION = os.getenv(\"NB_RUN_DATA_COLLECTION\", \"1\") == \"1\"\n",
    "RUN_DATASET_SPLIT  = os.getenv(\"NB_RUN_DATASET_SPLIT\",  \"1\") == \"1\"\n",
    "RUN_TRAINING       = os.getenv(\"NB_RUN_TRAINING\",       \"1\") == \"1\"\n",
    "RUN_INFERENCE      = os.getenv(\"NB_RUN_INFERENCE\",      \"1\") == \"1\"\n",
    "RUN_TRACKING       = os.getenv(\"NB_RUN_TRACKING\",       \"1\") == \"1\"\n",
    "\n",
    "# When runner is installed as a Windows Service, GUI (cv2.imshow) is usually not available.\n",
    "HEADLESS = os.getenv(\"NB_HEADLESS\", \"1\") == \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Run the cell below to start data collection.\n",
    "\n",
    "*   **[L]** Set Label\n",
    "*   **[S]** Save ROI\n",
    "*   **[C]** Clear ROI\n",
    "*   **[Q]** Quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self):\n",
    "        # 전역 변수 초기화\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        self.current_label = \"\"\n",
    "        self.save_count = 0\n",
    "        \n",
    "        # 데이터 저장 경로\n",
    "        self.BASE_DIR = \"dataset\"\n",
    "        self.METADATA_FILE = \"metadata.json\"\n",
    "        \n",
    "        # RealSense 파이프라인 설정\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        self.depth_scale = 0\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리 - ROI 선택\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "\n",
    "    def create_directory_structure(self):\n",
    "        \"\"\"데이터셋 디렉토리 구조 생성\"\"\"\n",
    "        if not os.path.exists(self.BASE_DIR):\n",
    "            os.makedirs(self.BASE_DIR)\n",
    "            print(f\"✓ 디렉토리 생성: {self.BASE_DIR}\")\n",
    "\n",
    "    def save_roi_data(self, color_image, depth_image, roi_coords):\n",
    "        \"\"\"ROI 데이터 저장\"\"\"\n",
    "        if not self.current_label:\n",
    "            print(\"⚠ 라벨이 설정되지 않았습니다. 먼저 라벨을 입력하세요.\")\n",
    "            return False\n",
    "        \n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        \n",
    "        # 클래스별 디렉토리 생성\n",
    "        class_dir = os.path.join(self.BASE_DIR, self.current_label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "            print(f\"✓ 새 클래스 디렉토리 생성: {class_dir}\")\n",
    "        \n",
    "        # 타임스탬프 생성\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        \n",
    "        # ROI 영역 추출\n",
    "        roi_color = color_image[y1:y2, x1:x2]\n",
    "        roi_depth = depth_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # 파일명 생성\n",
    "        color_filename = f\"{timestamp}_color.png\"\n",
    "        depth_filename = f\"{timestamp}_depth.png\"\n",
    "        \n",
    "        color_path = os.path.join(class_dir, color_filename)\n",
    "        depth_path = os.path.join(class_dir, depth_filename)\n",
    "        \n",
    "        # 이미지 저장\n",
    "        cv2.imwrite(color_path, roi_color)\n",
    "        \n",
    "        # Depth 이미지를 16-bit로 저장\n",
    "        cv2.imwrite(depth_path, roi_depth)\n",
    "        \n",
    "        # 메타데이터 저장\n",
    "        valid_depth = roi_depth[roi_depth > 0]\n",
    "        metadata = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"label\": self.current_label,\n",
    "            \"roi\": [x1, y1, x2, y2],\n",
    "            \"roi_size\": [x2 - x1, y2 - y1],\n",
    "            \"color_image\": color_filename,\n",
    "            \"depth_image\": depth_filename,\n",
    "            \"depth_avg\": float(np.mean(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "            \"depth_min\": float(np.min(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "            \"depth_max\": float(np.max(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "        }\n",
    "        \n",
    "        # 메타데이터 파일에 추가\n",
    "        metadata_path = os.path.join(class_dir, self.METADATA_FILE)\n",
    "        metadata_list = []\n",
    "        \n",
    "        if os.path.exists(metadata_path):\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                metadata_list = json.load(f)\n",
    "        \n",
    "        metadata_list.append(metadata)\n",
    "        \n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata_list, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        self.save_count += 1\n",
    "        print(f\"✓ 저장 완료 [{self.save_count}]: {self.current_label}/{color_filename}\")\n",
    "        return True\n",
    "\n",
    "    def draw_ui(self, image, roi_coords=None):\n",
    "        \"\"\"UI 요소 그리기\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # 상단 정보 패널\n",
    "        panel_height = 120\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (width, panel_height), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)\n",
    "        \n",
    "        # 제목\n",
    "        cv2.putText(image, \"Data Collector - RealSense ROI Labeling\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        # 현재 라벨 표시\n",
    "        label_text = f\"Current Label: {self.current_label if self.current_label else '[Not Set]'}\"\n",
    "        label_color = (0, 255, 0) if self.current_label else (0, 0, 255)\n",
    "        cv2.putText(image, label_text, (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, label_color, 2)\n",
    "        \n",
    "        # 저장 카운트\n",
    "        cv2.putText(image, f\"Saved: {self.save_count}\", (10, 90), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # 하단 도움말\n",
    "        help_y = height - 100\n",
    "        cv2.rectangle(image, (0, help_y), (width, height), (0, 0, 0), -1)\n",
    "        \n",
    "        help_texts = [\n",
    "            \"[ L ] Set Label  |  [ S ] Save ROI  |  [ C ] Clear ROI  |  [ Q ] Quit\",\n",
    "            \"Drag mouse to select ROI\"\n",
    "        ]\n",
    "        \n",
    "        for i, text in enumerate(help_texts):\n",
    "            cv2.putText(image, text, (10, help_y + 25 + i * 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # ROI 정보 표시\n",
    "        if roi_coords:\n",
    "            x1, y1, x2, y2 = roi_coords\n",
    "            roi_info = f\"ROI: ({x2-x1}x{y2-y1})\"\n",
    "            cv2.putText(image, roi_info, (width - 200, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    def run(self):\n",
    "        # 디렉토리 구조 생성\n",
    "        self.create_directory_structure()\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 깊이 스케일 가져오기\n",
    "        self.depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백 설정\n",
    "        cv2.namedWindow('Data Collector')\n",
    "        cv2.setMouseCallback('Data Collector', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"데이터 수집 프로그램 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. [L] 키를 눌러 라벨(클래스명) 입력\")\n",
    "        print(\"  2. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  3. [S] 키를 눌러 저장\")\n",
    "        print(\"  4. [C] 키로 ROI 초기화\")\n",
    "        print(\"  5. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지를 numpy 배열로 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지 복사\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # ROI 그리기\n",
    "                roi_coords = None\n",
    "                if self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # ROI 사각형 그리기\n",
    "                    color = (0, 255, 255) if self.is_drawing else (0, 255, 0)\n",
    "                    cv2.rectangle(display_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    \n",
    "                    # ROI 영역 반투명 오버레이\n",
    "                    if self.roi_selected and x2 > x1 and y2 > y1:\n",
    "                        overlay = display_image.copy()\n",
    "                        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), -1)\n",
    "                        cv2.addWeighted(overlay, 0.2, display_image, 0.8, 0, display_image)\n",
    "                \n",
    "                # UI 그리기\n",
    "                self.draw_ui(display_image, roi_coords)\n",
    "                \n",
    "                window_name = 'Data Collector'\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "\n",
    "                # 화면 표시\n",
    "                cv2.imshow(window_name, display_image)\n",
    "                \n",
    "                # 키 입력 처리\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                \n",
    "                if key == ord('q'):\n",
    "                    print(\"\\n프로그램을 종료합니다.\")\n",
    "                    break\n",
    "                    \n",
    "                elif key == ord('l'):\n",
    "                    # 라벨 입력\n",
    "                    print(\"\\n\" + \"-\" * 40)\n",
    "                    new_label = input(\"클래스 라벨을 입력하세요: \").strip()\n",
    "                    if new_label:\n",
    "                        self.current_label = new_label\n",
    "                        print(f\"✓ 라벨 설정: {self.current_label}\")\n",
    "                    else:\n",
    "                        print(\"⚠ 라벨이 비어있습니다.\")\n",
    "                    print(\"-\" * 40 + \"\\n\")\n",
    "                    \n",
    "                elif key == ord('s'):\n",
    "                    # ROI 저장\n",
    "                    if self.roi_selected and roi_coords:\n",
    "                        x1, y1, x2, y2 = roi_coords\n",
    "                        if x2 > x1 and y2 > y1:\n",
    "                            self.save_roi_data(color_image, depth_image, roi_coords)\n",
    "                        else:\n",
    "                            print(\"⚠ 유효하지 않은 ROI입니다.\")\n",
    "                    else:\n",
    "                        print(\"⚠ ROI를 먼저 선택하세요.\")\n",
    "                        \n",
    "                elif key == ord('c'):\n",
    "                    # ROI 초기화\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "                    print(\"✓ ROI 초기화\")\n",
    "        \n",
    "        finally:\n",
    "            # 정리\n",
    "            self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"총 {self.save_count}개의 샘플이 저장되었습니다.\")\n",
    "            print(f\"데이터 위치: {os.path.abspath(self.BASE_DIR)}\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "if \"RUN_DATA_COLLECTION\" in globals() and RUN_DATA_COLLECTION:\n",
    "    collector = DataCollector()\n",
    "    collector.run()\n",
    "else:\n",
    "    print(\"Skip data collection.(set RUN_DATA_COLLECTION=1 to run)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "Split the collected data into train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "데이터셋 유틸리티 - train/val/test 분할 및 데이터 로딩\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def split_dataset(source_dir=\"dataset\", output_dir=\"dataset_split\", \n",
    "                  train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    데이터셋을 train/val/test로 분할\n",
    "    \n",
    "    Args:\n",
    "        source_dir: 원본 데이터셋 디렉토리\n",
    "        output_dir: 분할된 데이터셋 저장 디렉토리\n",
    "        train_ratio: 학습 데이터 비율\n",
    "        val_ratio: 검증 데이터 비율\n",
    "        test_ratio: 테스트 데이터 비율\n",
    "        seed: 랜덤 시드\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 비율 검증\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \\\n",
    "        \"train_ratio + val_ratio + test_ratio must equal 1.0\"\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            print(f\"⚠ {split_dir} 이미 존재합니다. 건너뜁니다.\")\n",
    "        else:\n",
    "            os.makedirs(split_dir)\n",
    "    \n",
    "    # 클래스별 처리\n",
    "    class_dirs = [d for d in os.listdir(source_dir) \n",
    "                  if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    \n",
    "    print(f\"\\n발견된 클래스: {class_dirs}\")\n",
    "    print(f\"분할 비율 - Train: {train_ratio}, Val: {val_ratio}, Test: {test_ratio}\\n\")\n",
    "    \n",
    "    total_stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        \n",
    "        # 클래스별 이미지 파일 수집 (color 이미지만)\n",
    "        color_images = [f for f in os.listdir(class_path) \n",
    "                       if f.endswith('_color.png')]\n",
    "        \n",
    "        # 타임스탬프 추출 (중복 방지)\n",
    "        timestamps = list(set([img.replace('_color.png', '') for img in color_images]))\n",
    "        \n",
    "        # 셔플\n",
    "        random.shuffle(timestamps)\n",
    "        \n",
    "        # 분할 인덱스 계산\n",
    "        n_total = len(timestamps)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        \n",
    "        train_timestamps = timestamps[:n_train]\n",
    "        val_timestamps = timestamps[n_train:n_train + n_val]\n",
    "        test_timestamps = timestamps[n_train + n_val:]\n",
    "        \n",
    "        # 각 split에 복사\n",
    "        split_data = {\n",
    "            'train': train_timestamps,\n",
    "            'val': val_timestamps,\n",
    "            'test': test_timestamps\n",
    "        }\n",
    "        \n",
    "        for split, timestamps_list in split_data.items():\n",
    "            # 클래스 디렉토리 생성\n",
    "            split_class_dir = os.path.join(output_dir, split, class_name)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "            \n",
    "            # 파일 복사\n",
    "            for timestamp in timestamps_list:\n",
    "                # Color 이미지\n",
    "                color_src = os.path.join(class_path, f\"{timestamp}_color.png\")\n",
    "                color_dst = os.path.join(split_class_dir, f\"{timestamp}_color.png\")\n",
    "                \n",
    "                # Depth 이미지\n",
    "                depth_src = os.path.join(class_path, f\"{timestamp}_depth.png\")\n",
    "                depth_dst = os.path.join(split_class_dir, f\"{timestamp}_depth.png\")\n",
    "                \n",
    "                if os.path.exists(color_src):\n",
    "                    shutil.copy2(color_src, color_dst)\n",
    "                if os.path.exists(depth_src):\n",
    "                    shutil.copy2(depth_src, depth_dst)\n",
    "            \n",
    "            total_stats[split] += len(timestamps_list)\n",
    "            print(f\"  {class_name}/{split}: {len(timestamps_list)} samples\")\n",
    "    \n",
    "    print(f\"\\n총 분할 결과:\")\n",
    "    print(f\"  Train: {total_stats['train']} samples\")\n",
    "    print(f\"  Val: {total_stats['val']} samples\")\n",
    "    print(f\"  Test: {total_stats['test']} samples\")\n",
    "    print(f\"  Total: {sum(total_stats.values())} samples\")\n",
    "    print(f\"\\n✓ 데이터셋 분할 완료: {output_dir}\")\n",
    "\n",
    "def get_class_names(dataset_dir):\n",
    "    \"\"\"데이터셋에서 클래스 이름 추출\"\"\"\n",
    "    class_names = sorted([d for d in os.listdir(dataset_dir) \n",
    "                         if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "    return class_names\n",
    "\n",
    "def count_samples(dataset_dir):\n",
    "    \"\"\"데이터셋의 샘플 수 계산\"\"\"\n",
    "    class_names = get_class_names(dataset_dir)\n",
    "    stats = {}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        color_images = [f for f in os.listdir(class_path) \n",
    "                       if f.endswith('_color.png')]\n",
    "        stats[class_name] = len(color_images)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # 데이터셋 정보 출력\n",
    "    print(\"=\" * 60)\n",
    "    print(\"데이터셋 분석\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if os.path.exists(\"dataset\"):\n",
    "        stats = count_samples(\"dataset\")\n",
    "        print(\"\\n클래스별 샘플 수:\")\n",
    "        for class_name, count in stats.items():\n",
    "            print(f\"  {class_name}: {count} samples\")\n",
    "        print(f\"\\n총 샘플 수: {sum(stats.values())}\")\n",
    "        \n",
    "        # 데이터셋 분할\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"데이터셋 분할 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        split_dataset()\n",
    "    else:\n",
    "        print(\"⚠ dataset 폴더를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PyTorch Dataset 클래스 정의\n",
    "\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class RealSenseDataset(Dataset):\n",
    "    \"\"\"RealSense RGB-D 데이터셋\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None, use_depth=False, img_size=224):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: 데이터셋 루트 디렉토리 (train, val, test 중 하나)\n",
    "            transform: 이미지 변환 (torchvision.transforms)\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "            img_size: 이미지 크기 (정사각형)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.use_depth = use_depth\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # 클래스 이름 및 인덱스 매핑\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) \n",
    "                              if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # 샘플 수집\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            color_images = [f for f in os.listdir(class_dir) \n",
    "                           if f.endswith('_color.png')]\n",
    "            \n",
    "            for color_img in color_images:\n",
    "                timestamp = color_img.replace('_color.png', '')\n",
    "                color_path = os.path.join(class_dir, color_img)\n",
    "                depth_path = os.path.join(class_dir, f\"{timestamp}_depth.png\")\n",
    "                \n",
    "                # Depth 파일 존재 확인\n",
    "                if self.use_depth and not os.path.exists(depth_path):\n",
    "                    continue\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'color': color_path,\n",
    "                    'depth': depth_path if self.use_depth else None,\n",
    "                    'label': self.class_to_idx[class_name],\n",
    "                    'class_name': class_name\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Color 이미지 로드\n",
    "        color_image = cv2.imread(sample['color'])\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 이미지 크기 조정\n",
    "        color_image = cv2.resize(color_image, (self.img_size, self.img_size))\n",
    "        \n",
    "        if self.use_depth:\n",
    "            # Depth 이미지 로드\n",
    "            depth_image = cv2.imread(sample['depth'], cv2.IMREAD_UNCHANGED)\n",
    "            depth_image = cv2.resize(depth_image, (self.img_size, self.img_size))\n",
    "            \n",
    "            # Depth 정규화 (0-255 범위로)\n",
    "            depth_image = cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            depth_image = depth_image.astype(np.uint8)\n",
    "            \n",
    "            # RGB + D = 4채널\n",
    "            image = np.dstack([color_image, depth_image])\n",
    "        else:\n",
    "            image = color_image\n",
    "        \n",
    "        # PIL Image로 변환 (transforms 적용을 위해)\n",
    "        if self.use_depth:\n",
    "            # 4채널은 별도 처리\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        else:\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        label = sample['label']\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_name(self, idx):\n",
    "        \"\"\"인덱스로부터 클래스 이름 반환\"\"\"\n",
    "        return self.classes[idx]\n",
    "\n",
    "\n",
    "def get_transforms(img_size=224, augment=True):\n",
    "    \"\"\"\n",
    "    데이터 변환 정의\n",
    "    \n",
    "    Args:\n",
    "        img_size: 이미지 크기\n",
    "        augment: 데이터 증강 사용 여부\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        # 학습용 변환 (데이터 증강 포함)\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        # 검증/테스트용 변환\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "\n",
    "def test_dataset():\n",
    "    \"\"\"데이터셋 로드 테스트\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"데이터셋 테스트\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if os.path.exists(\"dataset_split/train\"):\n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "        train_dataset = RealSenseDataset(\"dataset_split/train\", \n",
    "                                        transform=train_transform,\n",
    "                                        use_depth=False)\n",
    "        \n",
    "        print(f\"\\n클래스: {train_dataset.classes}\")\n",
    "        print(f\"클래스 수: {len(train_dataset.classes)}\")\n",
    "        print(f\"학습 샘플 수: {len(train_dataset)}\")\n",
    "        \n",
    "        # 첫 번째 샘플 확인\n",
    "        if len(train_dataset) > 0:\n",
    "            image, label = train_dataset[0]\n",
    "            print(f\"\\n샘플 확인:\")\n",
    "            print(f\"  이미지 shape: {image.shape}\")\n",
    "            print(f\"  라벨: {label} ({train_dataset.get_class_name(label)})\")\n",
    "    else:\n",
    "        print(\"⚠ dataset_split/train 폴더를 찾을 수 없습니다.\")\n",
    "        print(\"먼저 dataset_utils.py를 실행하여 데이터셋을 분할하세요.\")\n",
    "\n",
    "if \"RUN_DATASET_SPLIT\" in globals() and RUN_DATASET_SPLIT:\n",
    "    split_dataset()\n",
    "\n",
    "    test_dataset()\n",
    "else:\n",
    "    print(\"Skip dataset split/test (set NB_RUN_DATASET_SPLIT=1 to enable).\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "Train the model using the collected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch 학습 스크립트\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# from dataset import RealSenseDataset, get_transforms\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"사용 디바이스: {self.device}\")\n",
    "        \n",
    "        # 데이터셋 로드\n",
    "        self.load_datasets()\n",
    "        \n",
    "        # 모델 생성\n",
    "        self.create_model()\n",
    "        \n",
    "        # Loss, Optimizer 설정\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        \n",
    "        # 학습 기록\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "    \n",
    "    def load_datasets(self):\n",
    "        \"\"\"데이터셋 로드\"\"\"\n",
    "        train_transform, val_transform = get_transforms(\n",
    "            img_size=self.config['img_size'],\n",
    "            augment=self.config['use_augmentation']\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = RealSenseDataset(\n",
    "            root_dir=self.config['train_dir'],\n",
    "            transform=train_transform,\n",
    "            use_depth=self.config['use_depth'],\n",
    "            img_size=self.config['img_size']\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = RealSenseDataset(\n",
    "            root_dir=self.config['val_dir'],\n",
    "            transform=val_transform,\n",
    "            use_depth=self.config['use_depth'],\n",
    "            img_size=self.config['img_size']\n",
    "        )\n",
    "        \n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=self.config['num_workers']\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=self.config['num_workers']\n",
    "        )\n",
    "        \n",
    "        self.num_classes = len(self.train_dataset.classes)\n",
    "        self.class_names = self.train_dataset.classes\n",
    "        \n",
    "        print(f\"\\n데이터셋 로드 완료:\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  학습 샘플: {len(self.train_dataset)}\")\n",
    "        print(f\"  검증 샘플: {len(self.val_dataset)}\")\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"모델 생성\"\"\"\n",
    "        model_name = self.config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 모델: {model_name}\")\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        print(f\"\\n모델 생성 완료: {model_name}\")\n",
    "        print(f\"  사전 학습 가중치: {'사용' if self.config['use_pretrained'] else '미사용'}\")\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"1 에폭 학습\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            \n",
    "            # Forward\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # 통계\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Progress bar 업데이트\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"검증\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc='Validation')\n",
    "            for images, labels in pbar:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                    'acc': f'{100.*correct/total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"전체 학습 루프\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"학습 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for epoch in range(self.config['num_epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # 학습\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # 검증\n",
    "            val_loss, val_acc = self.validate()\n",
    "            \n",
    "            # 학습률 조정\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # 기록\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"\\n결과:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # 최고 성능 모델 저장\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.save_checkpoint('best_model.pth', epoch, val_acc)\n",
    "                print(f\"  ✓ 최고 성능 모델 저장 (Val Acc: {val_acc:.2f}%)\")\n",
    "            \n",
    "            # Early Stopping (선택사항)\n",
    "            if self.config['early_stopping_patience'] > 0:\n",
    "                if epoch > self.config['early_stopping_patience']:\n",
    "                    recent_val_acc = self.history['val_acc'][-self.config['early_stopping_patience']:]\n",
    "                    if all(acc <= self.best_val_acc for acc in recent_val_acc):\n",
    "                        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "        \n",
    "        # 최종 모델 저장\n",
    "        self.save_checkpoint('final_model.pth', self.config['num_epochs'], val_acc)\n",
    "        \n",
    "        # 학습 기록 저장\n",
    "        self.save_history()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"학습 완료!\")\n",
    "        print(f\"최고 검증 정확도: {self.best_val_acc:.2f}%\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def save_checkpoint(self, filename, epoch, val_acc):\n",
    "        \"\"\"체크포인트 저장\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': self.class_names,\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        save_path = os.path.join(self.config['save_dir'], filename)\n",
    "        torch.save(checkpoint, save_path)\n",
    "    \n",
    "    def save_history(self):\n",
    "        \"\"\"학습 기록 저장\"\"\"\n",
    "        history_path = os.path.join(self.config['save_dir'], 'training_history.json')\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        print(f\"학습 기록 저장: {history_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 학습 설정\n",
    "    config = {\n",
    "        # 데이터\n",
    "        'train_dir': 'dataset_split/train',\n",
    "        'val_dir': 'dataset_split/val',\n",
    "        'img_size': 224,\n",
    "        'use_depth': False,  # Depth 정보 사용 여부\n",
    "        'use_augmentation': True,\n",
    "        \n",
    "        # 모델\n",
    "        'model_name': 'mobilenet_v2',  # 'resnet18', 'resnet50', 'mobilenet_v2'\n",
    "        'use_pretrained': True,  # Transfer Learning\n",
    "        \n",
    "        # 학습\n",
    "        'batch_size': 16,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'num_workers': 0,  # Windows Jupyter Notebook: 0으로 설정 (멀티프로세싱 이슈 방지)\n",
    "        'early_stopping_patience': 10,\n",
    "        \n",
    "        # 저장\n",
    "        'save_dir': 'models'\n",
    "    }\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    os.makedirs(config['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # 설정 출력\n",
    "    print(\"=\" * 60)\n",
    "    print(\"학습 설정\")\n",
    "    print(\"=\" * 60)\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # 학습 시작\n",
    "    trainer = Trainer(config)\n",
    "    trainer.train()\n",
    "\n",
    "if \"RUN_TRAINING\" in globals() and RUN_TRAINING:\n",
    "    main()\n",
    "else:\n",
    "    print(\"Skip training (set NB_RUN_TRAINING=1 to enable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference\n",
    "\n",
    "Real-time inference using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실시간 추론 프로그램 - RealSense ROI 판별\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "from PIL import Image\n",
    "\n",
    "class RealtimeInference:\n",
    "    def __init__(self, model_path, img_size=224, use_depth=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: 학습된 모델 경로\n",
    "            img_size: 입력 이미지 크기\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "        \"\"\"\n",
    "        self.img_size = img_size\n",
    "        self.use_depth = use_depth\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        # 이미지 전처리 변환\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # ROI 선택 상태\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        \n",
    "        print(f\"✓ 모델 로드 완료\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  디바이스: {self.device}\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"학습된 모델 로드\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # 설정 및 클래스 정보\n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # 모델 생성\n",
    "        model_name = config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=False)\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        # 가중치 로드\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "    \n",
    "    def preprocess_roi(self, color_image, roi_coords):\n",
    "        \"\"\"ROI 전처리\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        roi = color_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # BGR to RGB\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # PIL Image로 변환\n",
    "        roi_pil = Image.fromarray(roi_rgb)\n",
    "        \n",
    "        # Transform 적용\n",
    "        roi_tensor = self.transform(roi_pil)\n",
    "        roi_tensor = roi_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "        \n",
    "        return roi_tensor\n",
    "    \n",
    "    def predict(self, roi_tensor):\n",
    "        \"\"\"추론 수행\"\"\"\n",
    "        with torch.no_grad():\n",
    "            roi_tensor = roi_tensor.to(self.device)\n",
    "            outputs = self.model(roi_tensor)\n",
    "            \n",
    "            # Softmax로 확률 계산\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = predicted.item()\n",
    "            confidence_score = confidence.item()\n",
    "            \n",
    "            return predicted_class, confidence_score, probabilities[0].cpu().numpy()\n",
    "    \n",
    "    def draw_results(self, image, roi_coords, predicted_class, confidence, probabilities):\n",
    "        \"\"\"결과 시각화\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        \n",
    "        # ROI 사각형\n",
    "        color = (0, 255, 0) if confidence > 0.7 else (0, 165, 255)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # 예측 결과 텍스트\n",
    "        class_name = self.class_names[predicted_class]\n",
    "        result_text = f\"{class_name}: {confidence*100:.1f}%\"\n",
    "        \n",
    "        # 텍스트 배경\n",
    "        text_size = cv2.getTextSize(result_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10\n",
    "        \n",
    "        if text_y < 30:\n",
    "            text_y = y2 + 25\n",
    "        \n",
    "        # 배경 박스\n",
    "        cv2.rectangle(image, (text_x - 5, text_y - text_size[1] - 5),\n",
    "                     (text_x + text_size[0] + 5, text_y + 5),\n",
    "                     (0, 0, 0), -1)\n",
    "        \n",
    "        # 텍스트\n",
    "        cv2.putText(image, result_text, (text_x, text_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # 모든 클래스 확률 표시 (오른쪽 상단)\n",
    "        prob_y = 30\n",
    "        for i, (cls_name, prob) in enumerate(zip(self.class_names, probabilities)):\n",
    "            prob_text = f\"{cls_name}: {prob*100:.1f}%\"\n",
    "            prob_color = (0, 255, 0) if i == predicted_class else (200, 200, 200)\n",
    "            cv2.putText(image, prob_text, (image.shape[1] - 200, prob_y + i * 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, prob_color, 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"실시간 추론 실행\"\"\"\n",
    "        # RealSense 파이프라인 설정\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        \n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            pipeline.start(config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백\n",
    "        cv2.namedWindow('RealSense Inference')\n",
    "        cv2.setMouseCallback('RealSense Inference', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"실시간 추론 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  2. 자동으로 추론 결과 표시\")\n",
    "        print(\"  3. [C] 키로 ROI 초기화\")\n",
    "        print(\"  4. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # ROI 그리기 및 추론\n",
    "                if self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # 그리는 중\n",
    "                    if self.is_drawing:\n",
    "                        cv2.rectangle(display_image, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # 선택 완료 시 추론\n",
    "                    elif self.roi_selected and x2 > x1 + 10 and y2 > y1 + 10:\n",
    "                        # ROI 전처리\n",
    "                        roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                        \n",
    "                        # 추론\n",
    "                        predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                        \n",
    "                        # 결과 시각화\n",
    "                        self.draw_results(display_image, roi_coords, \n",
    "                                        predicted_class, confidence, probabilities)\n",
    "                \n",
    "                # UI 안내\n",
    "                cv2.putText(display_image, \"Drag to select ROI for inference\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(display_image, \"[C] Clear | [Q] Quit\", (10, 60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                \n",
    "                window_name = 'RealSense Inference'\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "\n",
    "                # 화면 표시\n",
    "                cv2.imshow(window_name, display_image)\n",
    "                \n",
    "                # 키 입력\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('c'):\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "        \n",
    "        finally:\n",
    "            pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\n프로그램 종료\")\n",
    "\n",
    "\n",
    "def inference_main():\n",
    "    # 모델 경로\n",
    "    model_path = \"models/best_model.pth\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERROR: 모델 파일을 찾을 수 없습니다: {model_path}\")\n",
    "        print(\"먼저 train.py를 실행하여 모델을 학습하세요.\")\n",
    "        return\n",
    "    \n",
    "    # 추론 실행\n",
    "    inference = RealtimeInference(model_path)\n",
    "    inference.run()\n",
    "\n",
    "\n",
    "if \"RUN_INFERENCE\" in globals() and RUN_INFERENCE:\n",
    "    inference_main()\n",
    "else:\n",
    "    print(\"Skip inference (set NB_RUN_INFERENCE=1 to enable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tracking\n",
    "\n",
    "Real-time object tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실시간 추론 + 객체 추적 프로그램\n",
    "한 번 분류된 객체를 자동으로 추적합니다.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "from PIL import Image\n",
    "\n",
    "class RealtimeInferenceWithTracking:\n",
    "    def __init__(self, model_path, img_size=224, use_depth=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: 학습된 모델 경로\n",
    "            img_size: 입력 이미지 크기\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "        \"\"\"\n",
    "        self.img_size = img_size\n",
    "        self.use_depth = use_depth\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        # 이미지 전처리 변환\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # ROI 선택 상태\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        \n",
    "        # 추적 상태\n",
    "        self.template = None\n",
    "        self.template_size = None\n",
    "        self.last_bbox = None\n",
    "        self.tracking = False\n",
    "        self.tracked_class = None\n",
    "        self.tracked_confidence = 0.0\n",
    "        self.tracked_probabilities = None\n",
    "        \n",
    "        print(f\"✓ 모델 로드 완료\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  디바이스: {self.device}\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"학습된 모델 로드\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # 설정 및 클래스 정보\n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # 모델 생성\n",
    "        model_name = config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=False)\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        # 가중치 로드\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "    \n",
    "    def preprocess_roi(self, color_image, roi_coords):\n",
    "        \"\"\"ROI 전처리\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        roi = color_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # BGR to RGB\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # PIL Image로 변환\n",
    "        roi_pil = Image.fromarray(roi_rgb)\n",
    "        \n",
    "        # Transform 적용\n",
    "        roi_tensor = self.transform(roi_pil)\n",
    "        roi_tensor = roi_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "        \n",
    "        return roi_tensor\n",
    "    \n",
    "    def predict(self, roi_tensor):\n",
    "        \"\"\"추론 수행\"\"\"\n",
    "        with torch.no_grad():\n",
    "            roi_tensor = roi_tensor.to(self.device)\n",
    "            outputs = self.model(roi_tensor)\n",
    "            \n",
    "            # Softmax로 확률 계산\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = predicted.item()\n",
    "            confidence_score = confidence.item()\n",
    "            \n",
    "            return predicted_class, confidence_score, probabilities[0].cpu().numpy()\n",
    "    \n",
    "    def init_tracker(self, frame, bbox):\n",
    "        \"\"\"트래커 초기화 - 템플릿 매칭 사용\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        \n",
    "        # 템플릿 저장 (추적할 영역)\n",
    "        self.template = frame[y:y+h, x:x+w].copy()\n",
    "        self.template_size = (w, h)\n",
    "        self.last_bbox = bbox\n",
    "        self.tracking = True\n",
    "        \n",
    "    def update_tracker(self, frame):\n",
    "        \"\"\"트래커 업데이트 - 템플릿 매칭으로 위치 찾기\"\"\"\n",
    "        if self.template is None:\n",
    "            return False, None\n",
    "        \n",
    "        # 이전 위치 주변에서 검색 (효율성)\n",
    "        x, y, w, h = [int(v) for v in self.last_bbox]\n",
    "        \n",
    "        # 검색 영역 설정 (이전 위치 ±50 픽셀)\n",
    "        search_margin = 50\n",
    "        x1 = max(0, x - search_margin)\n",
    "        y1 = max(0, y - search_margin)\n",
    "        x2 = min(frame.shape[1], x + w + search_margin)\n",
    "        y2 = min(frame.shape[0], y + h + search_margin)\n",
    "        \n",
    "        search_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # 템플릿 매칭\n",
    "        try:\n",
    "            result = cv2.matchTemplate(search_region, self.template, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "            \n",
    "            # 신뢰도 체크 (0.5 이상이면 성공)\n",
    "            if max_val > 0.5:\n",
    "                # 새로운 위치 계산\n",
    "                new_x = x1 + max_loc[0]\n",
    "                new_y = y1 + max_loc[1]\n",
    "                new_bbox = (new_x, new_y, w, h)\n",
    "                \n",
    "                # 위치 업데이트\n",
    "                self.last_bbox = new_bbox\n",
    "                \n",
    "                # 템플릿 업데이트 (적응형 추적)\n",
    "                self.template = frame[new_y:new_y+h, new_x:new_x+w].copy()\n",
    "                \n",
    "                return True, new_bbox\n",
    "            else:\n",
    "                return False, None\n",
    "        except:\n",
    "            return False, None\n",
    "    \n",
    "    def draw_results(self, image, bbox, predicted_class, confidence, probabilities, is_tracking=False):\n",
    "        \"\"\"결과 시각화\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "        \n",
    "        # 박스 색상 (추적 중이면 파란색, 아니면 초록/주황)\n",
    "        if is_tracking:\n",
    "            color = (255, 0, 0)  # 파란색 - 추적 중\n",
    "        else:\n",
    "            color = (0, 255, 0) if confidence > 0.7 else (0, 165, 255)\n",
    "        \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # 예측 결과 텍스트\n",
    "        class_name = self.class_names[predicted_class]\n",
    "        status = \"[TRACKING]\" if is_tracking else \"[DETECTED]\"\n",
    "        result_text = f\"{status} {class_name}: {confidence*100:.1f}%\"\n",
    "        \n",
    "        # 텍스트 배경\n",
    "        text_size = cv2.getTextSize(result_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10\n",
    "        \n",
    "        if text_y < 30:\n",
    "            text_y = y2 + 25\n",
    "        \n",
    "        # 배경 박스\n",
    "        cv2.rectangle(image, (text_x - 5, text_y - text_size[1] - 5),\n",
    "                     (text_x + text_size[0] + 5, text_y + 5),\n",
    "                     (0, 0, 0), -1)\n",
    "        \n",
    "        # 텍스트\n",
    "        cv2.putText(image, result_text, (text_x, text_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # 모든 클래스 확률 표시 (오른쪽 상단)\n",
    "        prob_y = 30\n",
    "        cv2.putText(image, \"Class Probabilities:\", (image.shape[1] - 220, prob_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        for i, (cls_name, prob) in enumerate(zip(self.class_names, probabilities)):\n",
    "            prob_text = f\"{cls_name}: {prob*100:.1f}%\"\n",
    "            prob_color = (0, 255, 0) if i == predicted_class else (200, 200, 200)\n",
    "            cv2.putText(image, prob_text, (image.shape[1] - 200, prob_y + (i+1) * 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, prob_color, 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"실시간 추론 + 추적 실행\"\"\"\n",
    "        # RealSense 파이프라인 설정\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        \n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            pipeline.start(config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백\n",
    "        cv2.namedWindow('RealSense Tracking')\n",
    "        cv2.setMouseCallback('RealSense Tracking', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"실시간 추론 + 추적 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  2. 자동으로 추론 및 추적 시작\")\n",
    "        print(\"  3. [T] 키로 추적 시작/중지\")\n",
    "        print(\"  4. [C] 키로 ROI 초기화\")\n",
    "        print(\"  5. [R] 키로 재분류 (추적 중)\")\n",
    "        print(\"  6. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # 추적 모드\n",
    "                if self.tracking and self.template is not None:\n",
    "                    # 트래커 업데이트\n",
    "                    success, bbox = self.update_tracker(color_image)\n",
    "                    \n",
    "                    if success:\n",
    "                        # 추적 성공 - 결과 표시\n",
    "                        self.draw_results(display_image, bbox, \n",
    "                                        self.tracked_class, \n",
    "                                        self.tracked_confidence,\n",
    "                                        self.tracked_probabilities,\n",
    "                                        is_tracking=True)\n",
    "                    else:\n",
    "                        # 추적 실패\n",
    "                        cv2.putText(display_image, \"Tracking Lost! Press [C] to reset\", \n",
    "                                   (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        self.tracking = False\n",
    "                        self.template = None\n",
    "                \n",
    "                # ROI 선택 모드\n",
    "                elif self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # 그리는 중\n",
    "                    if self.is_drawing:\n",
    "                        cv2.rectangle(display_image, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # 선택 완료 시 추론\n",
    "                    elif self.roi_selected and x2 > x1 + 10 and y2 > y1 + 10:\n",
    "                        # ROI 전처리\n",
    "                        roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                        \n",
    "                        # 추론\n",
    "                        predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                        \n",
    "                        # 결과 저장 (추적용)\n",
    "                        self.tracked_class = predicted_class\n",
    "                        self.tracked_confidence = confidence\n",
    "                        self.tracked_probabilities = probabilities\n",
    "                        \n",
    "                        # bbox 형식으로 변환 (x, y, w, h)\n",
    "                        bbox = (x1, y1, x2 - x1, y2 - y1)\n",
    "                        \n",
    "                        # 결과 시각화\n",
    "                        self.draw_results(display_image, bbox,\n",
    "                                        predicted_class, confidence, probabilities,\n",
    "                                        is_tracking=False)\n",
    "                \n",
    "                # UI 안내\n",
    "                status_y = 30\n",
    "                if self.tracking:\n",
    "                    cv2.putText(display_image, \"MODE: TRACKING\", (10, status_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(display_image, \"MODE: DETECTION\", (10, status_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.putText(display_image, \"[T] Track | [C] Clear | [R] Reclassify | [Q] Quit\", \n",
    "                           (10, status_y + 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # 화면 표시\n",
    "                window_name = 'RealSense Tracking'\n",
    "\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "                \n",
    "                # imshow() 호출 전에 닫힘을 먼저 확인하면, “닫자마자 imshow가 창을 재생성”하는 상황을 피할 수 있어요.\n",
    "                cv2.imshow(window_name, display_image)\n",
    "\n",
    "                # 키 입력\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('c'):\n",
    "                    # 초기화\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "                    self.tracking = False\n",
    "                    self.template = None\n",
    "                    print(\"✓ 초기화 완료\")\n",
    "                    \n",
    "                elif key == ord('t'):\n",
    "                    # 추적 시작/중지\n",
    "                    if not self.tracking and self.roi_selected:\n",
    "                        # 추적 시작\n",
    "                        x1 = min(self.roi_start[0], self.roi_end[0])\n",
    "                        y1 = min(self.roi_start[1], self.roi_end[1])\n",
    "                        x2 = max(self.roi_start[0], self.roi_end[0])\n",
    "                        y2 = max(self.roi_start[1], self.roi_end[1])\n",
    "                        \n",
    "                        bbox = (x1, y1, x2 - x1, y2 - y1)\n",
    "                        self.init_tracker(color_image, bbox)\n",
    "                        print(f\"✓ 추적 시작: {self.class_names[self.tracked_class]}\")\n",
    "                    else:\n",
    "                        # 추적 중지\n",
    "                        self.tracking = False\n",
    "                        self.template = None\n",
    "                        print(\"✓ 추적 중지\")\n",
    "                        \n",
    "                elif key == ord('r'):\n",
    "                    # 재분류 (추적 중일 때)\n",
    "                    if self.tracking and self.template is not None:\n",
    "                        success, bbox = self.update_tracker(color_image)\n",
    "                        if success:\n",
    "                            x, y, w, h = [int(v) for v in bbox]\n",
    "                            roi_coords = (x, y, x + w, y + h)\n",
    "                            \n",
    "                            # 재분류\n",
    "                            roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                            predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                            \n",
    "                            # 결과 업데이트\n",
    "                            self.tracked_class = predicted_class\n",
    "                            self.tracked_confidence = confidence\n",
    "                            self.tracked_probabilities = probabilities\n",
    "                            print(f\"✓ 재분류: {self.class_names[predicted_class]} ({confidence*100:.1f}%)\")\n",
    "        \n",
    "        finally:\n",
    "            pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\n프로그램 종료\")\n",
    "\n",
    "\n",
    "def tracking_main():\n",
    "    # 모델 경로\n",
    "    model_path = \"models/best_model.pth\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERROR: 모델 파일을 찾을 수 없습니다: {model_path}\")\n",
    "        print(\"먼저 2_2_train.py를 실행하여 모델을 학습하세요.\")\n",
    "        return\n",
    "    \n",
    "    # 추론 + 추적 실행\n",
    "    tracker = RealtimeInferenceWithTracking(model_path)\n",
    "    tracker.run()\n",
    "\n",
    "\n",
    "if \"RUN_TRACKING\" in globals() and RUN_TRACKING:\n",
    "    tracking_main()\n",
    "else:\n",
    "    print(\"Skip tracking (set NB_RUN_TRACKING=1 to enable).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

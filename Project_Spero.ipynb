{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Spero - RealSense Object Detection & Tracking\n",
    "\n",
    "### 이 노트북은 데이터 수집, 학습, 추론, 추적 모듈을 통합한 문서입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 변수 설명\n",
    "\n",
    "| 변수명 | 기본값 | 설명 |\n",
    "| -------- | -------- | ------ |\n",
    "| CI | False | CI/CD 환경 여부. \"1\", \"true\", \"yes\" 중 하나면 True |\n",
    "| NB_RUN_DATA_COLLECTION | True | 데이터 수집 모듈 실행 여부 |\n",
    "| NB_RUN_DATASET_SPLIT | True | 데이터셋 분할 모듈 실행 여부 |\n",
    "| NB_RUN_TRAINING | True | 모델 학습 모듈 실행 여부 |\n",
    "| NB_RUN_INFERENCE | True | 추론 모듈 실행 여부 |\n",
    "| NB_RUN_TRACKING | True | 추적 모듈 실행 여부 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import random\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===== CI / Notebook Execution Controls =====\n",
    "# These flags let GitHub Actions (papermill/nbclient) run the notebook safely.\n",
    "CI = os.getenv(\"CI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "RUN_DATA_COLLECTION = os.getenv(\"NB_RUN_DATA_COLLECTION\", \"1\") == \"1\"\n",
    "RUN_DATASET_SPLIT  = os.getenv(\"NB_RUN_DATASET_SPLIT\",  \"1\") == \"1\"\n",
    "RUN_TRAINING       = os.getenv(\"NB_RUN_TRAINING\",       \"1\") == \"1\"\n",
    "RUN_INFERENCE      = os.getenv(\"NB_RUN_INFERENCE\",      \"1\") == \"1\"\n",
    "RUN_TRACKING       = os.getenv(\"NB_RUN_TRACKING\",       \"1\") == \"1\"\n",
    "\n",
    "# When runner is installed as a Windows Service, GUI (cv2.imshow) is usually not available.\n",
    "HEADLESS = os.getenv(\"NB_HEADLESS\", \"1\") == \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "### 주요 기능\n",
    "- 실시간 스트리밍: RealSense 카메라의 **컬러 영상**과 **깊이(Depth) 영상을** 640x480 해상도로 시각화합니다.\n",
    "- ROI(Region of Interest) 선택: 마우스 드래그를 통해 이미지에서 데이터로 추출할 관심 영역을 자유롭게 지정할 수 있습니다.\n",
    "- 라벨링(Labeling): 수집할 데이터의 클래스 이름을 사용자로부터 입력받아 분류별로 저장합니다.\n",
    "- 데이터 자동 저장: 지정된 ROI 영역의 컬러 이미지(PNG), 깊이 이미지(16-bit PNG), 그리고 메타데이터(JSON)를 자동으로 생성하고 저장합니다.\n",
    "\n",
    "\n",
    "### 사용자 조작 가이드 (단축키)\n",
    "\n",
    "* **[L]** : 현재 수집중인 객체의 **라벨(클래스명) **을 입력합니다. (예: 'car', 'person', 'bike' 등)\n",
    "* ** 마우스 드래그**: 이미지 위에서 드래그하여 객체가 있는 ROI 영역을 선택합니다.\n",
    "* **[S]** : 현재 선택된 ROI 영역의 데이터를 저장합니다. (컬러/깊이 이미지 및 메타데이터)\n",
    "* **[C]** : 선택된 ROI 영역을 초기화(Clear) 합니다.\n",
    "* **[Q]** : 프로그램을 안전하게 종료합니다\n",
    "* **닫기 버튼**: 프로그램을 안전하게 종료합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self):\n",
    "        # 전역 변수 초기화\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        self.current_label = \"\"\n",
    "        self.save_count = 0\n",
    "        \n",
    "        # 데이터 저장 경로\n",
    "        self.BASE_DIR = \"dataset\"\n",
    "        self.METADATA_FILE = \"metadata.json\"\n",
    "        \n",
    "        # RealSense 파이프라인 설정\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        self.depth_scale = 0\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리 - ROI 선택\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "\n",
    "    def create_directory_structure(self):\n",
    "        \"\"\"데이터셋 디렉토리 구조 생성\"\"\"\n",
    "        if not os.path.exists(self.BASE_DIR):\n",
    "            os.makedirs(self.BASE_DIR)\n",
    "            print(f\"✓ 디렉토리 생성: {self.BASE_DIR}\")\n",
    "\n",
    "    def save_roi_data(self, color_image, depth_image, roi_coords):\n",
    "        \"\"\"ROI 데이터 저장\"\"\"\n",
    "        if not self.current_label:\n",
    "            print(\"⚠ 라벨이 설정되지 않았습니다. 먼저 라벨을 입력하세요.\")\n",
    "            return False\n",
    "        \n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        \n",
    "        # 클래스별 디렉토리 생성\n",
    "        class_dir = os.path.join(self.BASE_DIR, self.current_label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "            print(f\"✓ 새 클래스 디렉토리 생성: {class_dir}\")\n",
    "        \n",
    "        # 타임스탬프 생성\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        \n",
    "        # ROI 영역 추출\n",
    "        roi_color = color_image[y1:y2, x1:x2]\n",
    "        roi_depth = depth_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # 파일명 생성\n",
    "        color_filename = f\"{timestamp}_color.png\"\n",
    "        depth_filename = f\"{timestamp}_depth.png\"\n",
    "        \n",
    "        color_path = os.path.join(class_dir, color_filename)\n",
    "        depth_path = os.path.join(class_dir, depth_filename)\n",
    "        \n",
    "        # 이미지 저장\n",
    "        cv2.imwrite(color_path, roi_color)\n",
    "        \n",
    "        # Depth 이미지를 16-bit로 저장\n",
    "        cv2.imwrite(depth_path, roi_depth)\n",
    "        \n",
    "        # 메타데이터 저장\n",
    "        valid_depth = roi_depth[roi_depth > 0]\n",
    "        metadata = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"label\": self.current_label,\n",
    "            \"roi\": [x1, y1, x2, y2],\n",
    "            \"roi_size\": [x2 - x1, y2 - y1],\n",
    "            \"color_image\": color_filename,\n",
    "            \"depth_image\": depth_filename,\n",
    "            \"depth_avg\": float(np.mean(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "            \"depth_min\": float(np.min(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "            \"depth_max\": float(np.max(valid_depth) * self.depth_scale) if len(valid_depth) > 0 else 0.0,\n",
    "        }\n",
    "        \n",
    "        # 메타데이터 파일에 추가\n",
    "        metadata_path = os.path.join(class_dir, self.METADATA_FILE)\n",
    "        metadata_list = []\n",
    "        \n",
    "        if os.path.exists(metadata_path):\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                metadata_list = json.load(f)\n",
    "        \n",
    "        metadata_list.append(metadata)\n",
    "        \n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata_list, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        self.save_count += 1\n",
    "        print(f\"✓ 저장 완료 [{self.save_count}]: {self.current_label}/{color_filename}\")\n",
    "        return True\n",
    "\n",
    "    def draw_ui(self, image, roi_coords=None):\n",
    "        \"\"\"UI 요소 그리기\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # 상단 정보 패널\n",
    "        panel_height = 120\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (width, panel_height), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)\n",
    "        \n",
    "        # 제목\n",
    "        cv2.putText(image, \"Data Collector - RealSense ROI Labeling\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        # 현재 라벨 표시\n",
    "        label_text = f\"Current Label: {self.current_label if self.current_label else '[Not Set]'}\"\n",
    "        label_color = (0, 255, 0) if self.current_label else (0, 0, 255)\n",
    "        cv2.putText(image, label_text, (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, label_color, 2)\n",
    "        \n",
    "        # 저장 카운트\n",
    "        cv2.putText(image, f\"Saved: {self.save_count}\", (10, 90), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # 하단 도움말\n",
    "        help_y = height - 100\n",
    "        cv2.rectangle(image, (0, help_y), (width, height), (0, 0, 0), -1)\n",
    "        \n",
    "        help_texts = [\n",
    "            \"[ L ] Set Label  |  [ S ] Save ROI  |  [ C ] Clear ROI  |  [ Q ] Quit\",\n",
    "            \"Drag mouse to select ROI\"\n",
    "        ]\n",
    "        \n",
    "        for i, text in enumerate(help_texts):\n",
    "            cv2.putText(image, text, (10, help_y + 25 + i * 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # ROI 정보 표시\n",
    "        if roi_coords:\n",
    "            x1, y1, x2, y2 = roi_coords\n",
    "            roi_info = f\"ROI: ({x2-x1}x{y2-y1})\"\n",
    "            cv2.putText(image, roi_info, (width - 200, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    def run(self):\n",
    "        # 디렉토리 구조 생성\n",
    "        self.create_directory_structure()\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 깊이 스케일 가져오기\n",
    "        self.depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백 설정\n",
    "        cv2.namedWindow('Data Collector')\n",
    "        cv2.setMouseCallback('Data Collector', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"데이터 수집 프로그램 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. [L] 키를 눌러 라벨(클래스명) 입력\")\n",
    "        print(\"  2. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  3. [S] 키를 눌러 저장\")\n",
    "        print(\"  4. [C] 키로 ROI 초기화\")\n",
    "        print(\"  5. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지를 numpy 배열로 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지 복사\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # ROI 그리기\n",
    "                roi_coords = None\n",
    "                if self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # ROI 사각형 그리기\n",
    "                    color = (0, 255, 255) if self.is_drawing else (0, 255, 0)\n",
    "                    cv2.rectangle(display_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    \n",
    "                    # ROI 영역 반투명 오버레이\n",
    "                    if self.roi_selected and x2 > x1 and y2 > y1:\n",
    "                        overlay = display_image.copy()\n",
    "                        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), -1)\n",
    "                        cv2.addWeighted(overlay, 0.2, display_image, 0.8, 0, display_image)\n",
    "                \n",
    "                # UI 그리기\n",
    "                self.draw_ui(display_image, roi_coords)\n",
    "                \n",
    "                window_name = 'Data Collector'\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "\n",
    "                # 화면 표시\n",
    "                cv2.imshow(window_name, display_image)\n",
    "                \n",
    "                # 키 입력 처리\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                \n",
    "                if key == ord('q'):\n",
    "                    print(\"\\n프로그램을 종료합니다.\")\n",
    "                    break\n",
    "                    \n",
    "                elif key == ord('l'):\n",
    "                    # 라벨 입력\n",
    "                    print(\"\\n\" + \"-\" * 40)\n",
    "                    new_label = input(\"클래스 라벨을 입력하세요: \").strip()\n",
    "                    if new_label:\n",
    "                        self.current_label = new_label\n",
    "                        print(f\"✓ 라벨 설정: {self.current_label}\")\n",
    "                    else:\n",
    "                        print(\"⚠ 라벨이 비어있습니다.\")\n",
    "                    print(\"-\" * 40 + \"\\n\")\n",
    "                    \n",
    "                elif key == ord('s'):\n",
    "                    # ROI 저장\n",
    "                    if self.roi_selected and roi_coords:\n",
    "                        x1, y1, x2, y2 = roi_coords\n",
    "                        if x2 > x1 and y2 > y1:\n",
    "                            self.save_roi_data(color_image, depth_image, roi_coords)\n",
    "                        else:\n",
    "                            print(\"⚠ 유효하지 않은 ROI입니다.\")\n",
    "                    else:\n",
    "                        print(\"⚠ ROI를 먼저 선택하세요.\")\n",
    "                        \n",
    "                elif key == ord('c'):\n",
    "                    # ROI 초기화\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "                    print(\"✓ ROI 초기화\")\n",
    "        \n",
    "        finally:\n",
    "            # 정리\n",
    "            self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"총 {self.save_count}개의 샘플이 저장되었습니다.\")\n",
    "            print(f\"데이터 위치: {os.path.abspath(self.BASE_DIR)}\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "if \"RUN_DATA_COLLECTION\" in globals() and RUN_DATA_COLLECTION:\n",
    "    collector = DataCollector()\n",
    "    collector.run()\n",
    "else:\n",
    "    print(\"Skip data collection.(set RUN_DATA_COLLECTION=1 to run)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "** \"수집된 데이터를 섞고 나누어서, 인공지능이 학습할 수 있는 만반의 준비를 마치는 과정\" **이 한 번에 수행됩니다.\n",
    "\n",
    "### 데이터셋 분할\n",
    "- 수집된 원본 데이터(dataset/)를 학습(Train), 검증(Val), 테스트(Test)용 폴더(dataset_split/)로 자동 분리합니다.\n",
    "- 기본적으로 Train(학습): 70%, Val(검증): 15%, Test(테스트): 15% 비율로 나누며, 랜덤 시드(Seed)를 고정하여 항상 동일하게 분할되도록 보장합니다.\n",
    "- 모델이 학습하지 않은 데이터로 성능을 공정하게 평가할 수 있는 기반을 마련합니다.\n",
    "\n",
    "### 데이터셋 테스트\n",
    "- Train 및 Val 데이터셋을 로드해보고, 데이터 개수가 몇 개인지, 어떤 클래스가 감지되었는지 출력하여 정상을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "데이터셋 유틸리티 - train/val/test 분할 및 데이터 로딩\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def split_dataset(source_dir=\"dataset\", output_dir=\"dataset_split\", \n",
    "                  train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    데이터셋을 train/val/test로 분할\n",
    "    \n",
    "    Args:\n",
    "        source_dir: 원본 데이터셋 디렉토리\n",
    "        output_dir: 분할된 데이터셋 저장 디렉토리\n",
    "        train_ratio: 학습 데이터 비율\n",
    "        val_ratio: 검증 데이터 비율\n",
    "        test_ratio: 테스트 데이터 비율\n",
    "        seed: 랜덤 시드\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 비율 검증\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \\\n",
    "        \"train_ratio + val_ratio + test_ratio must equal 1.0\"\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            print(f\"⚠ {split_dir} 이미 존재합니다. 건너뜁니다.\")\n",
    "        else:\n",
    "            os.makedirs(split_dir)\n",
    "    \n",
    "    # 클래스별 처리\n",
    "    class_dirs = [d for d in os.listdir(source_dir) \n",
    "                  if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    \n",
    "    print(f\"\\n발견된 클래스: {class_dirs}\")\n",
    "    print(f\"분할 비율 - Train: {train_ratio}, Val: {val_ratio}, Test: {test_ratio}\\n\")\n",
    "    \n",
    "    total_stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        \n",
    "        # 클래스별 이미지 파일 수집 (color 이미지만)\n",
    "        color_images = [f for f in os.listdir(class_path) \n",
    "                       if f.endswith('_color.png')]\n",
    "        \n",
    "        # 타임스탬프 추출 (중복 방지)\n",
    "        timestamps = list(set([img.replace('_color.png', '') for img in color_images]))\n",
    "        \n",
    "        # 셔플\n",
    "        random.shuffle(timestamps)\n",
    "        \n",
    "        # 분할 인덱스 계산\n",
    "        n_total = len(timestamps)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        \n",
    "        train_timestamps = timestamps[:n_train]\n",
    "        val_timestamps = timestamps[n_train:n_train + n_val]\n",
    "        test_timestamps = timestamps[n_train + n_val:]\n",
    "        \n",
    "        # 각 split에 복사\n",
    "        split_data = {\n",
    "            'train': train_timestamps,\n",
    "            'val': val_timestamps,\n",
    "            'test': test_timestamps\n",
    "        }\n",
    "        \n",
    "        for split, timestamps_list in split_data.items():\n",
    "            # 클래스 디렉토리 생성\n",
    "            split_class_dir = os.path.join(output_dir, split, class_name)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "            \n",
    "            # 파일 복사\n",
    "            for timestamp in timestamps_list:\n",
    "                # Color 이미지\n",
    "                color_src = os.path.join(class_path, f\"{timestamp}_color.png\")\n",
    "                color_dst = os.path.join(split_class_dir, f\"{timestamp}_color.png\")\n",
    "                \n",
    "                # Depth 이미지\n",
    "                depth_src = os.path.join(class_path, f\"{timestamp}_depth.png\")\n",
    "                depth_dst = os.path.join(split_class_dir, f\"{timestamp}_depth.png\")\n",
    "                \n",
    "                if os.path.exists(color_src):\n",
    "                    shutil.copy2(color_src, color_dst)\n",
    "                if os.path.exists(depth_src):\n",
    "                    shutil.copy2(depth_src, depth_dst)\n",
    "            \n",
    "            total_stats[split] += len(timestamps_list)\n",
    "            print(f\"  {class_name}/{split}: {len(timestamps_list)} samples\")\n",
    "    \n",
    "    print(f\"\\n총 분할 결과:\")\n",
    "    print(f\"  Train: {total_stats['train']} samples\")\n",
    "    print(f\"  Val: {total_stats['val']} samples\")\n",
    "    print(f\"  Test: {total_stats['test']} samples\")\n",
    "    print(f\"  Total: {sum(total_stats.values())} samples\")\n",
    "    print(f\"\\n✓ 데이터셋 분할 완료: {output_dir}\")\n",
    "\n",
    "def get_class_names(dataset_dir):\n",
    "    \"\"\"데이터셋에서 클래스 이름 추출\"\"\"\n",
    "    class_names = sorted([d for d in os.listdir(dataset_dir) \n",
    "                         if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "    return class_names\n",
    "\n",
    "def count_samples(dataset_dir):\n",
    "    \"\"\"데이터셋의 샘플 수 계산\"\"\"\n",
    "    class_names = get_class_names(dataset_dir)\n",
    "    stats = {}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        color_images = [f for f in os.listdir(class_path) \n",
    "                       if f.endswith('_color.png')]\n",
    "        stats[class_name] = len(color_images)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # 데이터셋 정보 출력\n",
    "    print(\"=\" * 60)\n",
    "    print(\"데이터셋 분석\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if os.path.exists(\"dataset\"):\n",
    "        stats = count_samples(\"dataset\")\n",
    "        print(\"\\n클래스별 샘플 수:\")\n",
    "        for class_name, count in stats.items():\n",
    "            print(f\"  {class_name}: {count} samples\")\n",
    "        print(f\"\\n총 샘플 수: {sum(stats.values())}\")\n",
    "        \n",
    "        # 데이터셋 분할\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"데이터셋 분할 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        split_dataset()\n",
    "    else:\n",
    "        print(\"⚠ dataset 폴더를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PyTorch Dataset 클래스 정의\n",
    "\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class RealSenseDataset(Dataset):\n",
    "    \"\"\"RealSense RGB-D 데이터셋\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None, use_depth=False, img_size=224):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: 데이터셋 루트 디렉토리 (train, val, test 중 하나)\n",
    "            transform: 이미지 변환 (torchvision.transforms)\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "            img_size: 이미지 크기 (정사각형)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.use_depth = use_depth\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # 클래스 이름 및 인덱스 매핑\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) \n",
    "                              if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # 샘플 수집\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            color_images = [f for f in os.listdir(class_dir) \n",
    "                           if f.endswith('_color.png')]\n",
    "            \n",
    "            for color_img in color_images:\n",
    "                timestamp = color_img.replace('_color.png', '')\n",
    "                color_path = os.path.join(class_dir, color_img)\n",
    "                depth_path = os.path.join(class_dir, f\"{timestamp}_depth.png\")\n",
    "                \n",
    "                # Depth 파일 존재 확인\n",
    "                if self.use_depth and not os.path.exists(depth_path):\n",
    "                    continue\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'color': color_path,\n",
    "                    'depth': depth_path if self.use_depth else None,\n",
    "                    'label': self.class_to_idx[class_name],\n",
    "                    'class_name': class_name\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Color 이미지 로드\n",
    "        color_image = cv2.imread(sample['color'])\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 이미지 크기 조정\n",
    "        color_image = cv2.resize(color_image, (self.img_size, self.img_size))\n",
    "        \n",
    "        if self.use_depth:\n",
    "            # Depth 이미지 로드\n",
    "            depth_image = cv2.imread(sample['depth'], cv2.IMREAD_UNCHANGED)\n",
    "            depth_image = cv2.resize(depth_image, (self.img_size, self.img_size))\n",
    "            \n",
    "            # Depth 정규화 (0-255 범위로)\n",
    "            depth_image = cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            depth_image = depth_image.astype(np.uint8)\n",
    "            \n",
    "            # RGB + D = 4채널\n",
    "            image = np.dstack([color_image, depth_image])\n",
    "        else:\n",
    "            image = color_image\n",
    "        \n",
    "        # PIL Image로 변환 (transforms 적용을 위해)\n",
    "        if self.use_depth:\n",
    "            # 4채널은 별도 처리\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        else:\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        label = sample['label']\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_name(self, idx):\n",
    "        \"\"\"인덱스로부터 클래스 이름 반환\"\"\"\n",
    "        return self.classes[idx]\n",
    "\n",
    "\n",
    "def get_transforms(img_size=224, augment=True):\n",
    "    \"\"\"\n",
    "    데이터 변환 정의\n",
    "    \n",
    "    Args:\n",
    "        img_size: 이미지 크기\n",
    "        augment: 데이터 증강 사용 여부\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        # 학습용 변환 (데이터 증강 포함)\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        # 검증/테스트용 변환\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "\n",
    "def test_dataset():\n",
    "    \"\"\"데이터셋 로드 테스트\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"데이터셋 테스트\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if os.path.exists(\"dataset_split/train\"):\n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "        train_dataset = RealSenseDataset(\"dataset_split/train\", \n",
    "                                        transform=train_transform,\n",
    "                                        use_depth=False)\n",
    "        \n",
    "        print(f\"\\n클래스: {train_dataset.classes}\")\n",
    "        print(f\"클래스 수: {len(train_dataset.classes)}\")\n",
    "        print(f\"학습 샘플 수: {len(train_dataset)}\")\n",
    "        \n",
    "        # 첫 번째 샘플 확인\n",
    "        if len(train_dataset) > 0:\n",
    "            image, label = train_dataset[0]\n",
    "            print(f\"\\n샘플 확인:\")\n",
    "            print(f\"  이미지 shape: {image.shape}\")\n",
    "            print(f\"  라벨: {label} ({train_dataset.get_class_name(label)})\")\n",
    "    else:\n",
    "        print(\"⚠ dataset_split/train 폴더를 찾을 수 없습니다.\")\n",
    "        print(\"먼저 dataset_utils.py를 실행하여 데이터셋을 분할하세요.\")\n",
    "\n",
    "if \"RUN_DATASET_SPLIT\" in globals() and RUN_DATASET_SPLIT:\n",
    "    split_dataset()\n",
    "\n",
    "    test_dataset()\n",
    "else:\n",
    "    print(\"Skip dataset split/test (set NB_RUN_DATASET_SPLIT=1 to enable).\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "### 데이터 준비 (Data Loader)\n",
    "- dataset.RealSenseDataset 커스텀 데이터셋 사용합니다.\n",
    "- Train: Augmentation 적용 (Flip, Rotation 등) + Shuffle, 일반화(Generalization) 성능을 확보하고 과적합(Overfitting)을 방지합니다.\n",
    "- Validation: Resize/Normalize + No Shuffle, 평가의 일관성을 유지합니다.\n",
    "\n",
    "### 모델 아키텍처 (Model Construction)\n",
    "- Transfer Learning: Pre-trained (MobileNetV2 등) Backbone 사용\n",
    "- Fine-tuning: 마지막 FC Layer를 현재 클래스 수(num_classes)에 맞게 교체\n",
    "\n",
    "### 최적화 전략 (Optimization)\n",
    "- Loss: CrossEntropyLoss (Multi-class Classification)\n",
    "- Optimizer: Adam (Adaptive Moment Estimation)\n",
    "- Scheduler: ReduceLROnPlateau (Validation Loss 정체 시 LR 감소)\n",
    "\n",
    "### 학습 파이프라인 (Training Loop)\n",
    "- Train Step: Forward -> Loss -> Backward -> Optimizer Step\n",
    "- Validation Step: no_grad() 상태로 Inference -> 성능 평가 (Loss/Acc)\n",
    "- Monitoring: tqdm으로 진행률 및 실시간 지표 표시\n",
    "\n",
    "### 모델 관리 (Model Management)\n",
    "- Best Model Saving: Validation Accuracy 최고점 갱신 시 best_model.pth 저장\n",
    "- Early Stopping: 성능 개선 없을 시 (patience=10) 조기 종료\n",
    "- Log: 학습 이력(Loss/Acc) JSON 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch 학습 스크립트\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# from dataset import RealSenseDataset, get_transforms\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"사용 디바이스: {self.device}\")\n",
    "        \n",
    "        # 데이터셋 로드\n",
    "        self.load_datasets()\n",
    "        \n",
    "        # 모델 생성\n",
    "        self.create_model()\n",
    "        \n",
    "        # Loss, Optimizer 설정\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        \n",
    "        # 학습 기록\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "    \n",
    "    def load_datasets(self):\n",
    "        \"\"\"데이터셋 로드\"\"\"\n",
    "        train_transform, val_transform = get_transforms(\n",
    "            img_size=self.config['img_size'],\n",
    "            augment=self.config['use_augmentation']\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = RealSenseDataset(\n",
    "            root_dir=self.config['train_dir'],\n",
    "            transform=train_transform,\n",
    "            use_depth=self.config['use_depth'],\n",
    "            img_size=self.config['img_size']\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = RealSenseDataset(\n",
    "            root_dir=self.config['val_dir'],\n",
    "            transform=val_transform,\n",
    "            use_depth=self.config['use_depth'],\n",
    "            img_size=self.config['img_size']\n",
    "        )\n",
    "        \n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=self.config['num_workers']\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=self.config['num_workers']\n",
    "        )\n",
    "        \n",
    "        self.num_classes = len(self.train_dataset.classes)\n",
    "        self.class_names = self.train_dataset.classes\n",
    "        \n",
    "        print(f\"\\n데이터셋 로드 완료:\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  학습 샘플: {len(self.train_dataset)}\")\n",
    "        print(f\"  검증 샘플: {len(self.val_dataset)}\")\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"모델 생성\"\"\"\n",
    "        model_name = self.config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=self.config['use_pretrained'])\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 모델: {model_name}\")\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        print(f\"\\n모델 생성 완료: {model_name}\")\n",
    "        print(f\"  사전 학습 가중치: {'사용' if self.config['use_pretrained'] else '미사용'}\")\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"1 에폭 학습\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            \n",
    "            # Forward\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # 통계\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Progress bar 업데이트\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"검증\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc='Validation')\n",
    "            for images, labels in pbar:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                    'acc': f'{100.*correct/total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"전체 학습 루프\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"학습 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for epoch in range(self.config['num_epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # 학습\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # 검증\n",
    "            val_loss, val_acc = self.validate()\n",
    "            \n",
    "            # 학습률 조정\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # 기록\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"\\n결과:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # 최고 성능 모델 저장\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.save_checkpoint('best_model.pth', epoch, val_acc)\n",
    "                print(f\"  ✓ 최고 성능 모델 저장 (Val Acc: {val_acc:.2f}%)\")\n",
    "            \n",
    "            # Early Stopping (선택사항)\n",
    "            if self.config['early_stopping_patience'] > 0:\n",
    "                if epoch > self.config['early_stopping_patience']:\n",
    "                    recent_val_acc = self.history['val_acc'][-self.config['early_stopping_patience']:]\n",
    "                    if all(acc <= self.best_val_acc for acc in recent_val_acc):\n",
    "                        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "        \n",
    "        # 최종 모델 저장\n",
    "        self.save_checkpoint('final_model.pth', self.config['num_epochs'], val_acc)\n",
    "        \n",
    "        # 학습 기록 저장\n",
    "        self.save_history()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"학습 완료!\")\n",
    "        print(f\"최고 검증 정확도: {self.best_val_acc:.2f}%\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def save_checkpoint(self, filename, epoch, val_acc):\n",
    "        \"\"\"체크포인트 저장\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': self.class_names,\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        save_path = os.path.join(self.config['save_dir'], filename)\n",
    "        torch.save(checkpoint, save_path)\n",
    "    \n",
    "    def save_history(self):\n",
    "        \"\"\"학습 기록 저장\"\"\"\n",
    "        history_path = os.path.join(self.config['save_dir'], 'training_history.json')\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        print(f\"학습 기록 저장: {history_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 학습 설정\n",
    "    config = {\n",
    "        # 데이터\n",
    "        'train_dir': 'dataset_split/train',\n",
    "        'val_dir': 'dataset_split/val',\n",
    "        'img_size': 224,\n",
    "        'use_depth': False,  # Depth 정보 사용 여부\n",
    "        'use_augmentation': True,\n",
    "        \n",
    "        # 모델\n",
    "        'model_name': 'mobilenet_v2',  # 'resnet18', 'resnet50', 'mobilenet_v2'\n",
    "        'use_pretrained': True,  # Transfer Learning\n",
    "        \n",
    "        # 학습\n",
    "        'batch_size': 16,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'num_workers': 0,  # Windows Jupyter Notebook: 0으로 설정 (멀티프로세싱 이슈 방지)\n",
    "        'early_stopping_patience': 10,\n",
    "        \n",
    "        # 저장\n",
    "        'save_dir': 'models'\n",
    "    }\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    os.makedirs(config['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # 설정 출력\n",
    "    print(\"=\" * 60)\n",
    "    print(\"학습 설정\")\n",
    "    print(\"=\" * 60)\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # 학습 시작\n",
    "    trainer = Trainer(config)\n",
    "    trainer.train()\n",
    "\n",
    "if \"RUN_TRAINING\" in globals() and RUN_TRAINING:\n",
    "    main()\n",
    "else:\n",
    "    print(\"Skip training (set NB_RUN_TRAINING=1 to enable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference\n",
    "\n",
    "### 개요\n",
    "- RealSense 카메라로 실시간 영상을 받아 사용자가 선택한 ROI(관심 영역)의 객체를 분류한다.\n",
    "\n",
    "### 주요 기능\n",
    "- 모델 로드: 학습된 모델(ResNet18/50, MobileNetV2) 불러오기\n",
    "-  ROI 선택: 마우스 드래그로 관심 영역 지정\n",
    "- 실시간 추론: 선택된 영역의 객체 클래스 분류\n",
    "- 결과 시각화: 클래스명, 신뢰도, 전체 확률 화면 표시\n",
    "\n",
    "### 키 조작\n",
    "- **마우스 드래그**: ROI 영역 선택\n",
    "- **[C]**:  ROI 초기화\n",
    "- **[Q]** : 프로그램 종료\n",
    "- **X 버튼**: 윈도우 닫기로 종료\n",
    "\n",
    "### 실행 조건\n",
    "- models/best_model.pth 파일 필요 (학습 완료된 모델)\n",
    "- RealSense 카메라 연결 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실시간 추론 프로그램 - RealSense ROI 판별\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "from PIL import Image\n",
    "\n",
    "class RealtimeInference:\n",
    "    def __init__(self, model_path, img_size=224, use_depth=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: 학습된 모델 경로\n",
    "            img_size: 입력 이미지 크기\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "        \"\"\"\n",
    "        self.img_size = img_size\n",
    "        self.use_depth = use_depth\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        # 이미지 전처리 변환\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # ROI 선택 상태\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        \n",
    "        print(f\"✓ 모델 로드 완료\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  디바이스: {self.device}\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"학습된 모델 로드\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # 설정 및 클래스 정보\n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # 모델 생성\n",
    "        model_name = config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=False)\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        # 가중치 로드\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "    \n",
    "    def preprocess_roi(self, color_image, roi_coords):\n",
    "        \"\"\"ROI 전처리\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        roi = color_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # BGR to RGB\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # PIL Image로 변환\n",
    "        roi_pil = Image.fromarray(roi_rgb)\n",
    "        \n",
    "        # Transform 적용\n",
    "        roi_tensor = self.transform(roi_pil)\n",
    "        roi_tensor = roi_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "        \n",
    "        return roi_tensor\n",
    "    \n",
    "    def predict(self, roi_tensor):\n",
    "        \"\"\"추론 수행\"\"\"\n",
    "        with torch.no_grad():\n",
    "            roi_tensor = roi_tensor.to(self.device)\n",
    "            outputs = self.model(roi_tensor)\n",
    "            \n",
    "            # Softmax로 확률 계산\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = predicted.item()\n",
    "            confidence_score = confidence.item()\n",
    "            \n",
    "            return predicted_class, confidence_score, probabilities[0].cpu().numpy()\n",
    "    \n",
    "    def draw_results(self, image, roi_coords, predicted_class, confidence, probabilities):\n",
    "        \"\"\"결과 시각화\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        \n",
    "        # ROI 사각형\n",
    "        color = (0, 255, 0) if confidence > 0.7 else (0, 165, 255)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # 예측 결과 텍스트\n",
    "        class_name = self.class_names[predicted_class]\n",
    "        result_text = f\"{class_name}: {confidence*100:.1f}%\"\n",
    "        \n",
    "        # 텍스트 배경\n",
    "        text_size = cv2.getTextSize(result_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10\n",
    "        \n",
    "        if text_y < 30:\n",
    "            text_y = y2 + 25\n",
    "        \n",
    "        # 배경 박스\n",
    "        cv2.rectangle(image, (text_x - 5, text_y - text_size[1] - 5),\n",
    "                     (text_x + text_size[0] + 5, text_y + 5),\n",
    "                     (0, 0, 0), -1)\n",
    "        \n",
    "        # 텍스트\n",
    "        cv2.putText(image, result_text, (text_x, text_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # 모든 클래스 확률 표시 (오른쪽 상단)\n",
    "        prob_y = 30\n",
    "        for i, (cls_name, prob) in enumerate(zip(self.class_names, probabilities)):\n",
    "            prob_text = f\"{cls_name}: {prob*100:.1f}%\"\n",
    "            prob_color = (0, 255, 0) if i == predicted_class else (200, 200, 200)\n",
    "            cv2.putText(image, prob_text, (image.shape[1] - 200, prob_y + i * 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, prob_color, 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"실시간 추론 실행\"\"\"\n",
    "        # RealSense 파이프라인 설정\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        \n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            pipeline.start(config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백\n",
    "        cv2.namedWindow('RealSense Inference')\n",
    "        cv2.setMouseCallback('RealSense Inference', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"실시간 추론 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  2. 자동으로 추론 결과 표시\")\n",
    "        print(\"  3. [C] 키로 ROI 초기화\")\n",
    "        print(\"  4. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # ROI 그리기 및 추론\n",
    "                if self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # 그리는 중\n",
    "                    if self.is_drawing:\n",
    "                        cv2.rectangle(display_image, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # 선택 완료 시 추론\n",
    "                    elif self.roi_selected and x2 > x1 + 10 and y2 > y1 + 10:\n",
    "                        # ROI 전처리\n",
    "                        roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                        \n",
    "                        # 추론\n",
    "                        predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                        \n",
    "                        # 결과 시각화\n",
    "                        self.draw_results(display_image, roi_coords, \n",
    "                                        predicted_class, confidence, probabilities)\n",
    "                \n",
    "                # UI 안내\n",
    "                cv2.putText(display_image, \"Drag to select ROI for inference\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(display_image, \"[C] Clear | [Q] Quit\", (10, 60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                \n",
    "                window_name = 'RealSense Inference'\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "\n",
    "                # 화면 표시\n",
    "                cv2.imshow(window_name, display_image)\n",
    "                \n",
    "                # 키 입력\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('c'):\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "        \n",
    "        finally:\n",
    "            pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\n프로그램 종료\")\n",
    "\n",
    "\n",
    "def inference_main():\n",
    "    # 모델 경로\n",
    "    model_path = \"models/best_model.pth\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERROR: 모델 파일을 찾을 수 없습니다: {model_path}\")\n",
    "        print(\"먼저 train.py를 실행하여 모델을 학습하세요.\")\n",
    "        return\n",
    "    \n",
    "    # 추론 실행\n",
    "    inference = RealtimeInference(model_path)\n",
    "    inference.run()\n",
    "\n",
    "\n",
    "if \"RUN_INFERENCE\" in globals() and RUN_INFERENCE:\n",
    "    inference_main()\n",
    "else:\n",
    "    print(\"Skip inference (set NB_RUN_INFERENCE=1 to enable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tracking\n",
    "\n",
    "### 개요\n",
    "RealSense 카메라로 실시간 영상을 받아 객체를 분류하고, 템플릿 매칭 기반으로 해당 객체를 지속 추적한다.\n",
    "\n",
    "### 주요 기능\n",
    "- 모델 로드: 학습된 분류 모델(ResNet18/50, MobileNetV2) 불러오기\n",
    "- ROI 선택: 마우스 드래그로 추적할 객체 영역 지정\n",
    "- 객체 분류: 선택된 ROI의 클래스 판별\n",
    "- 템플릿 매칭 추적: 분류된 객체를 프레임마다 자동 추적\n",
    "- 결과 시각화: 추적 상태, 클래스명, 신뢰도 화면 표시\n",
    "\n",
    "\n",
    "### 추적 방식\n",
    "- 사용자가 ROI 선택 시 해당 영역을 템플릿으로 저장\n",
    "- 매 프레임마다 이전 위치 주변(±50px)에서 템플릿 매칭 수행\n",
    "- 매칭 신뢰도 0.5 이상이면 추적 성공으로 판정\n",
    "- 추적 성공 시 템플릿 갱신 (적응형 추적)\n",
    "\n",
    "\n",
    "### 키 조작\n",
    "- **마우스 드래그**: ROI 영역 선택\n",
    "- **[T]**: 추적 시작/중지\n",
    "- **[C]**: ROI 및 추적 초기화\n",
    "- **[R]**: 추적 중 객체 재분류\n",
    "- **[Q]**: 프로그램 종료\n",
    "- **X 버튼**: 윈도우 닫기로 종료\n",
    "\n",
    "### Inference와의 차이점\n",
    "- Inference: ROI 선택 → 1회 분류 → 결과 표시\n",
    "- Tracking: ROI 선택 → 분류 → 연속 추적 (객체가 이동해도 따라감)\n",
    "\n",
    "### 실행 조건\n",
    "- models/best_model.pth 파일 필요\n",
    "- RealSense 카메라 연결 필요\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실시간 추론 + 객체 추적 프로그램\n",
    "한 번 분류된 객체를 자동으로 추적합니다.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "from PIL import Image\n",
    "\n",
    "class RealtimeInferenceWithTracking:\n",
    "    def __init__(self, model_path, img_size=224, use_depth=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: 학습된 모델 경로\n",
    "            img_size: 입력 이미지 크기\n",
    "            use_depth: Depth 정보 사용 여부\n",
    "        \"\"\"\n",
    "        self.img_size = img_size\n",
    "        self.use_depth = use_depth\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        # 이미지 전처리 변환\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # ROI 선택 상태\n",
    "        self.roi_start = None\n",
    "        self.roi_end = None\n",
    "        self.is_drawing = False\n",
    "        self.roi_selected = False\n",
    "        \n",
    "        # 추적 상태\n",
    "        self.template = None\n",
    "        self.template_size = None\n",
    "        self.last_bbox = None\n",
    "        self.tracking = False\n",
    "        self.tracked_class = None\n",
    "        self.tracked_confidence = 0.0\n",
    "        self.tracked_probabilities = None\n",
    "        \n",
    "        print(f\"✓ 모델 로드 완료\")\n",
    "        print(f\"  클래스: {self.class_names}\")\n",
    "        print(f\"  디바이스: {self.device}\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"학습된 모델 로드\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # 설정 및 클래스 정보\n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # 모델 생성\n",
    "        model_name = config['model_name']\n",
    "        \n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=False)\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, self.num_classes)\n",
    "            \n",
    "        elif model_name == 'mobilenet_v2':\n",
    "            self.model = models.mobilenet_v2(pretrained=False)\n",
    "            in_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        # 가중치 로드\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"마우스 이벤트 처리\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.is_drawing = True\n",
    "            self.roi_start = (x, y)\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = False\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.is_drawing:\n",
    "                self.roi_end = (x, y)\n",
    "                \n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.is_drawing = False\n",
    "            self.roi_end = (x, y)\n",
    "            self.roi_selected = True\n",
    "    \n",
    "    def preprocess_roi(self, color_image, roi_coords):\n",
    "        \"\"\"ROI 전처리\"\"\"\n",
    "        x1, y1, x2, y2 = roi_coords\n",
    "        roi = color_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # BGR to RGB\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # PIL Image로 변환\n",
    "        roi_pil = Image.fromarray(roi_rgb)\n",
    "        \n",
    "        # Transform 적용\n",
    "        roi_tensor = self.transform(roi_pil)\n",
    "        roi_tensor = roi_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "        \n",
    "        return roi_tensor\n",
    "    \n",
    "    def predict(self, roi_tensor):\n",
    "        \"\"\"추론 수행\"\"\"\n",
    "        with torch.no_grad():\n",
    "            roi_tensor = roi_tensor.to(self.device)\n",
    "            outputs = self.model(roi_tensor)\n",
    "            \n",
    "            # Softmax로 확률 계산\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = predicted.item()\n",
    "            confidence_score = confidence.item()\n",
    "            \n",
    "            return predicted_class, confidence_score, probabilities[0].cpu().numpy()\n",
    "    \n",
    "    def init_tracker(self, frame, bbox):\n",
    "        \"\"\"트래커 초기화 - 템플릿 매칭 사용\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        \n",
    "        # 템플릿 저장 (추적할 영역)\n",
    "        self.template = frame[y:y+h, x:x+w].copy()\n",
    "        self.template_size = (w, h)\n",
    "        self.last_bbox = bbox\n",
    "        self.tracking = True\n",
    "        \n",
    "    def update_tracker(self, frame):\n",
    "        \"\"\"트래커 업데이트 - 템플릿 매칭으로 위치 찾기\"\"\"\n",
    "        if self.template is None:\n",
    "            return False, None\n",
    "        \n",
    "        # 이전 위치 주변에서 검색 (효율성)\n",
    "        x, y, w, h = [int(v) for v in self.last_bbox]\n",
    "        \n",
    "        # 검색 영역 설정 (이전 위치 ±50 픽셀)\n",
    "        search_margin = 50\n",
    "        x1 = max(0, x - search_margin)\n",
    "        y1 = max(0, y - search_margin)\n",
    "        x2 = min(frame.shape[1], x + w + search_margin)\n",
    "        y2 = min(frame.shape[0], y + h + search_margin)\n",
    "        \n",
    "        search_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # 템플릿 매칭\n",
    "        try:\n",
    "            result = cv2.matchTemplate(search_region, self.template, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "            \n",
    "            # 신뢰도 체크 (0.5 이상이면 성공)\n",
    "            if max_val > 0.5:\n",
    "                # 새로운 위치 계산\n",
    "                new_x = x1 + max_loc[0]\n",
    "                new_y = y1 + max_loc[1]\n",
    "                new_bbox = (new_x, new_y, w, h)\n",
    "                \n",
    "                # 위치 업데이트\n",
    "                self.last_bbox = new_bbox\n",
    "                \n",
    "                # 템플릿 업데이트 (적응형 추적)\n",
    "                self.template = frame[new_y:new_y+h, new_x:new_x+w].copy()\n",
    "                \n",
    "                return True, new_bbox\n",
    "            else:\n",
    "                return False, None\n",
    "        except:\n",
    "            return False, None\n",
    "    \n",
    "    def draw_results(self, image, bbox, predicted_class, confidence, probabilities, is_tracking=False):\n",
    "        \"\"\"결과 시각화\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "        \n",
    "        # 박스 색상 (추적 중이면 파란색, 아니면 초록/주황)\n",
    "        if is_tracking:\n",
    "            color = (255, 0, 0)  # 파란색 - 추적 중\n",
    "        else:\n",
    "            color = (0, 255, 0) if confidence > 0.7 else (0, 165, 255)\n",
    "        \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # 예측 결과 텍스트\n",
    "        class_name = self.class_names[predicted_class]\n",
    "        status = \"[TRACKING]\" if is_tracking else \"[DETECTED]\"\n",
    "        result_text = f\"{status} {class_name}: {confidence*100:.1f}%\"\n",
    "        \n",
    "        # 텍스트 배경\n",
    "        text_size = cv2.getTextSize(result_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10\n",
    "        \n",
    "        if text_y < 30:\n",
    "            text_y = y2 + 25\n",
    "        \n",
    "        # 배경 박스\n",
    "        cv2.rectangle(image, (text_x - 5, text_y - text_size[1] - 5),\n",
    "                     (text_x + text_size[0] + 5, text_y + 5),\n",
    "                     (0, 0, 0), -1)\n",
    "        \n",
    "        # 텍스트\n",
    "        cv2.putText(image, result_text, (text_x, text_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # 모든 클래스 확률 표시 (오른쪽 상단)\n",
    "        prob_y = 30\n",
    "        cv2.putText(image, \"Class Probabilities:\", (image.shape[1] - 220, prob_y),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        for i, (cls_name, prob) in enumerate(zip(self.class_names, probabilities)):\n",
    "            prob_text = f\"{cls_name}: {prob*100:.1f}%\"\n",
    "            prob_color = (0, 255, 0) if i == predicted_class else (200, 200, 200)\n",
    "            cv2.putText(image, prob_text, (image.shape[1] - 200, prob_y + (i+1) * 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, prob_color, 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"실시간 추론 + 추적 실행\"\"\"\n",
    "        # RealSense 파이프라인 설정\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        \n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        \n",
    "        # 스트리밍 시작\n",
    "        try:\n",
    "            pipeline.start(config)\n",
    "        except RuntimeError as e:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ERROR: RealSense 카메라를 찾을 수 없습니다!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\n다음 사항을 확인해주세요:\")\n",
    "            print(\"  1. RealSense 카메라가 USB 포트에 연결되어 있는지 확인\")\n",
    "            print(\"  2. 카메라의 LED가 켜져 있는지 확인\")\n",
    "            print(\"  3. 다른 프로그램에서 카메라를 사용 중인지 확인\")\n",
    "            print(\"\\n원본 에러 메시지:\", str(e))\n",
    "            print(\"=\" * 60)\n",
    "            return\n",
    "        \n",
    "        # 윈도우 생성 및 마우스 콜백\n",
    "        cv2.namedWindow('RealSense Tracking')\n",
    "        cv2.setMouseCallback('RealSense Tracking', self.mouse_callback)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"실시간 추론 + 추적 시작\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"사용법:\")\n",
    "        print(\"  1. 마우스로 드래그하여 ROI 선택\")\n",
    "        print(\"  2. 자동으로 추론 및 추적 시작\")\n",
    "        print(\"  3. [T] 키로 추적 시작/중지\")\n",
    "        print(\"  4. [C] 키로 ROI 초기화\")\n",
    "        print(\"  5. [R] 키로 재분류 (추적 중)\")\n",
    "        print(\"  6. [Q] 키로 종료\")\n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # 프레임 대기\n",
    "                frames = pipeline.wait_for_frames()\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                color_frame = frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지 변환\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                \n",
    "                # 표시용 이미지\n",
    "                display_image = color_image.copy()\n",
    "                \n",
    "                # 추적 모드\n",
    "                if self.tracking and self.template is not None:\n",
    "                    # 트래커 업데이트\n",
    "                    success, bbox = self.update_tracker(color_image)\n",
    "                    \n",
    "                    if success:\n",
    "                        # 추적 성공 - 결과 표시\n",
    "                        self.draw_results(display_image, bbox, \n",
    "                                        self.tracked_class, \n",
    "                                        self.tracked_confidence,\n",
    "                                        self.tracked_probabilities,\n",
    "                                        is_tracking=True)\n",
    "                    else:\n",
    "                        # 추적 실패\n",
    "                        cv2.putText(display_image, \"Tracking Lost! Press [C] to reset\", \n",
    "                                   (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        self.tracking = False\n",
    "                        self.template = None\n",
    "                \n",
    "                # ROI 선택 모드\n",
    "                elif self.roi_start is not None and self.roi_end is not None:\n",
    "                    x1 = max(0, min(self.roi_start[0], self.roi_end[0]))\n",
    "                    y1 = max(0, min(self.roi_start[1], self.roi_end[1]))\n",
    "                    x2 = min(639, max(self.roi_start[0], self.roi_end[0]))\n",
    "                    y2 = min(479, max(self.roi_start[1], self.roi_end[1]))\n",
    "                    \n",
    "                    roi_coords = (x1, y1, x2, y2)\n",
    "                    \n",
    "                    # 그리는 중\n",
    "                    if self.is_drawing:\n",
    "                        cv2.rectangle(display_image, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # 선택 완료 시 추론\n",
    "                    elif self.roi_selected and x2 > x1 + 10 and y2 > y1 + 10:\n",
    "                        # ROI 전처리\n",
    "                        roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                        \n",
    "                        # 추론\n",
    "                        predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                        \n",
    "                        # 결과 저장 (추적용)\n",
    "                        self.tracked_class = predicted_class\n",
    "                        self.tracked_confidence = confidence\n",
    "                        self.tracked_probabilities = probabilities\n",
    "                        \n",
    "                        # bbox 형식으로 변환 (x, y, w, h)\n",
    "                        bbox = (x1, y1, x2 - x1, y2 - y1)\n",
    "                        \n",
    "                        # 결과 시각화\n",
    "                        self.draw_results(display_image, bbox,\n",
    "                                        predicted_class, confidence, probabilities,\n",
    "                                        is_tracking=False)\n",
    "                \n",
    "                # UI 안내\n",
    "                status_y = 30\n",
    "                if self.tracking:\n",
    "                    cv2.putText(display_image, \"MODE: TRACKING\", (10, status_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(display_image, \"MODE: DETECTION\", (10, status_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.putText(display_image, \"[T] Track | [C] Clear | [R] Reclassify | [Q] Quit\", \n",
    "                           (10, status_y + 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # 화면 표시\n",
    "                window_name = 'RealSense Tracking'\n",
    "\n",
    "                # 윈도우 닫기 버튼(X) 클릭 감지\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "                \n",
    "                # imshow() 호출 전에 닫힘을 먼저 확인하면, “닫자마자 imshow가 창을 재생성”하는 상황을 피할 수 있어요.\n",
    "                cv2.imshow(window_name, display_image)\n",
    "\n",
    "                # 키 입력\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('c'):\n",
    "                    # 초기화\n",
    "                    self.roi_start = None\n",
    "                    self.roi_end = None\n",
    "                    self.is_drawing = False\n",
    "                    self.roi_selected = False\n",
    "                    self.tracking = False\n",
    "                    self.template = None\n",
    "                    print(\"✓ 초기화 완료\")\n",
    "                    \n",
    "                elif key == ord('t'):\n",
    "                    # 추적 시작/중지\n",
    "                    if not self.tracking and self.roi_selected:\n",
    "                        # 추적 시작\n",
    "                        x1 = min(self.roi_start[0], self.roi_end[0])\n",
    "                        y1 = min(self.roi_start[1], self.roi_end[1])\n",
    "                        x2 = max(self.roi_start[0], self.roi_end[0])\n",
    "                        y2 = max(self.roi_start[1], self.roi_end[1])\n",
    "                        \n",
    "                        bbox = (x1, y1, x2 - x1, y2 - y1)\n",
    "                        self.init_tracker(color_image, bbox)\n",
    "                        print(f\"✓ 추적 시작: {self.class_names[self.tracked_class]}\")\n",
    "                    else:\n",
    "                        # 추적 중지\n",
    "                        self.tracking = False\n",
    "                        self.template = None\n",
    "                        print(\"✓ 추적 중지\")\n",
    "                        \n",
    "                elif key == ord('r'):\n",
    "                    # 재분류 (추적 중일 때)\n",
    "                    if self.tracking and self.template is not None:\n",
    "                        success, bbox = self.update_tracker(color_image)\n",
    "                        if success:\n",
    "                            x, y, w, h = [int(v) for v in bbox]\n",
    "                            roi_coords = (x, y, x + w, y + h)\n",
    "                            \n",
    "                            # 재분류\n",
    "                            roi_tensor = self.preprocess_roi(color_image, roi_coords)\n",
    "                            predicted_class, confidence, probabilities = self.predict(roi_tensor)\n",
    "                            \n",
    "                            # 결과 업데이트\n",
    "                            self.tracked_class = predicted_class\n",
    "                            self.tracked_confidence = confidence\n",
    "                            self.tracked_probabilities = probabilities\n",
    "                            print(f\"✓ 재분류: {self.class_names[predicted_class]} ({confidence*100:.1f}%)\")\n",
    "        \n",
    "        finally:\n",
    "            pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\n프로그램 종료\")\n",
    "\n",
    "\n",
    "def tracking_main():\n",
    "    # 모델 경로\n",
    "    model_path = \"models/best_model.pth\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERROR: 모델 파일을 찾을 수 없습니다: {model_path}\")\n",
    "        print(\"먼저 2_2_train.py를 실행하여 모델을 학습하세요.\")\n",
    "        return\n",
    "    \n",
    "    # 추론 + 추적 실행\n",
    "    tracker = RealtimeInferenceWithTracking(model_path)\n",
    "    tracker.run()\n",
    "\n",
    "\n",
    "if \"RUN_TRACKING\" in globals() and RUN_TRACKING:\n",
    "    tracking_main()\n",
    "else:\n",
    "    print(\"Skip tracking (set NB_RUN_TRACKING=1 to enable).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
